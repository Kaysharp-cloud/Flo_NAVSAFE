{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fde5544b",
   "metadata": {},
   "source": [
    "# Evaluate NWM Short Range Forecasts Made for Current Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0618b5c6",
   "metadata": {},
   "source": [
    "**Author(s):** \n",
    "\n",
    "<ul style=\"line-height:1.5;\">\n",
    "<li>Nana Oye Djan <a href=\"mailto:ndjan@andrew.cmu.edu\">(ndjan@andrew.cmu.edu)</a></li>\n",
    "</ul>\n",
    "\n",
    "**Last Updated:** \n",
    "17th July 2025\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "This notebook provides code to retrieve NOAA National Water Model Short Range data from Amazon Web Services (AWS) in netcdf format at the current time as well as retrieve instantaneous USGS gage data (discharge) for reaches in Travis County to evaluate the performance of the NWM forecasts made in previous initialization runs for the current time.\n",
    "\n",
    "**Description:**\n",
    "\n",
    "This notebook determines the reaches USGS gages are on in Travis County using OWP's <a href=\"https://github.com/NOAA-OWP/hydrotools\">(hydrotools)</a></li>, uses the reach feature ids to download the short range forecast and uses the USGS site ids to get the instantaneous discharge readings for those sites. It then evaluates the performance of the NWM short range forecasts made in previous initialization runs for the current time using the Continuous Ranked Probability Score to evaluate the accuracy and precision of the short range forecasts and percentage bias to determine the degree of over or underestimation of the short range forecasts.\n",
    "\n",
    "**Data Description:**\n",
    "\n",
    "This notebook uses data developed and published by NOAA on Amazon Web Services (AWS) as described in detail in <a href=\"https://registry.opendata.aws/noaa-nwm-pds/\">(this registry)</a></li> of open data entry. The National Water Model (NWM) is a water resources model that simulates and forecasts water budget variables, including snowpack, evapotranspiration, soil moisture and streamflow, over the entire continental United States (CONUS). It is operated by NOAA’s Office of Water Prediction. This bucket contains a four-week rollover of the Short Range Forecast model output and the corresponding forcing data for the model. The model is forced with meteorological data from the High Resolution Rapid Refresh (HRRR) and the Rapid Refresh (RAP) models. The Short Range Forecast configuration cycles hourly and produces hourly deterministic forecasts of streamflow and hydrologic states out to 18 hours. It also uses information on USGS reaches in Travis County provided <a href=\"http://www.hydroshare.org/resource/c95e654312204ce0b4d8e31e71cd4354\">(here)</a></li>\n",
    "\n",
    "**Software Requirements:**\n",
    "\n",
    "This notebook uses Python v3.10.14 and requires the following specific Python libraries: \n",
    "\n",
    "> nest_asyncio: 1.6.0 \\\n",
    "   numpy: 1.26.4 \\\n",
    "   pandas: 2.3.0 \\\n",
    "   geopandas: 0.14.4 \\\n",
    "   dataretrieval: 1.0.12 \\\n",
    "   scores: 1.0.2 \\\n",
    "   xarray: 2025.4.0 \\\n",
    "   s3fs: 2025.5.1 \\\n",
    "   fsspec: 2025.5.1 \\\n",
    "   ipython: 8.37.0 \\\n",
    "   os: Python 3.10.14 (stdlib) \\\n",
    "   datetime / timedelta: Python 3.10.14 (stdlib) \\\n",
    "   re: Python 3.10.14 (stdlib) \n",
    " \n",
    "\n",
    "**Disclosure**\n",
    "The code contained in this notebook was partially created and revised by ChatGPT, an AI language model developed by OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa232a0c",
   "metadata": {},
   "source": [
    "#### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b1fb811c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary packages\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from hydrotools.nwm_client.NWMFileClient import NWMFileClient, QueryError, NWMClient\n",
    "from dataretrieval import nwis\n",
    "from scores.probability import crps_for_ensemble\n",
    "from datetime import datetime, timedelta\n",
    "import xarray as xr\n",
    "import s3fs\n",
    "from IPython.display import display\n",
    "import fsspec\n",
    "import os, re\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519b8539",
   "metadata": {},
   "source": [
    "#### 2. Define Important Parameters and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "50b5df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#S3 bucket info\n",
    "s3_bucket = 'noaa-nwm-pds'\n",
    "forecast_path = 'short_range'\n",
    "variable = 'streamflow'\n",
    "filename = 'channel_rt'\n",
    "valid_time = datetime.utcnow()\n",
    "max_lead_hours = 10\n",
    "CFS_TO_M3S    = 0.028316846592  # ft³/s → m³/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "29f80dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL builder function\n",
    "def construct_s3_url(cycle_dt: datetime, lead_hr: int) -> str:\n",
    "    \"\"\"\n",
    "    Build the S3 URL for:\n",
    "      nwm.t{HH}z.short_range.{filename}.f{LLL}.conus.nc\n",
    "    \"\"\"\n",
    "    date_str = cycle_dt.strftime(\"%Y%m%d\")      # e.g. '20250708'\n",
    "    cycle_hr = f\"{cycle_dt.hour:02d}\"           # e.g. '16'\n",
    "    lead_str = f\"{lead_hr:03d}\"                 # e.g. '005'\n",
    "    fname    = (\n",
    "        f\"nwm.t{cycle_hr}z.short_range.\"\n",
    "        f\"{filename}.f{lead_str}.conus.nc\"\n",
    "    )\n",
    "    return f\"s3://{s3_bucket}/nwm.{date_str}/{forecast_path}/{fname}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d2a89d",
   "metadata": {},
   "source": [
    "#### 3. Crosswalk USGS -> NWM Feature IDS to subset gauges in Travis County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ed5180",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load gauge shapefile and extract USGS IDs\n",
    "stations = gpd.read_file(\n",
    "    \"/path/to/NWPS_Gages/NWPSGagesTravisCounty_All.shp\"\n",
    ")\n",
    "stations[\"usgs_id\"] = stations[\"usgs_id\"].astype(str).str.zfill(8)\n",
    "site_ids = stations[\"usgs_id\"].tolist()\n",
    "\n",
    "# Build the NWM ↔ USGS crosswalk\n",
    "nwm_client = NWMFileClient()\n",
    "raw_cw = (\n",
    "    nwm_client.crosswalk\n",
    "      .reset_index()\n",
    "      .rename(columns={\"index\":\"nwm_feature_id\"})\n",
    "      [[\"nwm_feature_id\",\"usgs_site_code\"]]\n",
    ")\n",
    "cw = raw_cw[raw_cw[\"usgs_site_code\"].isin(site_ids)]\n",
    "nwm_ids_int = cw[\"nwm_feature_id\"].astype(int).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f288cb22",
   "metadata": {},
   "source": [
    "#### 4. Get SR forecasts made for current day and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "efa5ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize filesystem\n",
    "fs = s3fs.S3FileSystem(anon=True, client_kwargs={\"region_name\":\"us-east-1\"})\n",
    "today = datetime.utcnow().date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "802729a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using folder noaa-nwm-pds/nwm.20250714/short_range/ with cycles: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]Z\n",
      "✔ Using t14Z run for current forecasts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_id</th>\n",
       "      <th>valid_time</th>\n",
       "      <th>lead_hour</th>\n",
       "      <th>streamflow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5673157</td>\n",
       "      <td>2025-07-14 15:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5781203</td>\n",
       "      <td>2025-07-14 15:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5781223</td>\n",
       "      <td>2025-07-14 15:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5781313</td>\n",
       "      <td>2025-07-14 15:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5781319</td>\n",
       "      <td>2025-07-14 15:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature_id          valid_time  lead_hour  streamflow\n",
       "0    5673157 2025-07-14 15:00:00          1        0.08\n",
       "1    5781203 2025-07-14 15:00:00          1        0.08\n",
       "2    5781223 2025-07-14 15:00:00          1        0.03\n",
       "3    5781313 2025-07-14 15:00:00          1        0.32\n",
       "4    5781319 2025-07-14 15:00:00          1        0.02"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble valid_time chosen: 2025-07-14 16:00:00\n",
      "✔ Got 10-member ensemble for current time\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_id</th>\n",
       "      <th>forecast_run</th>\n",
       "      <th>lead_hour</th>\n",
       "      <th>streamflow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5673157</td>\n",
       "      <td>2025-07-14 14:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5781203</td>\n",
       "      <td>2025-07-14 14:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5781223</td>\n",
       "      <td>2025-07-14 14:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5781313</td>\n",
       "      <td>2025-07-14 14:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5781319</td>\n",
       "      <td>2025-07-14 14:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5781345</td>\n",
       "      <td>2025-07-14 14:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5781709</td>\n",
       "      <td>2025-07-14 14:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5781703</td>\n",
       "      <td>2025-07-14 14:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5781731</td>\n",
       "      <td>2025-07-14 14:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5781373</td>\n",
       "      <td>2025-07-14 14:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature_id        forecast_run  lead_hour  streamflow\n",
       "0    5673157 2025-07-14 14:00:00          2        0.09\n",
       "1    5781203 2025-07-14 14:00:00          2        0.09\n",
       "2    5781223 2025-07-14 14:00:00          2        0.03\n",
       "3    5781313 2025-07-14 14:00:00          2        0.32\n",
       "4    5781319 2025-07-14 14:00:00          2        0.04\n",
       "5    5781345 2025-07-14 14:00:00          2        0.25\n",
       "6    5781709 2025-07-14 14:00:00          2        0.02\n",
       "7    5781703 2025-07-14 14:00:00          2        0.03\n",
       "8    5781731 2025-07-14 14:00:00          2        0.07\n",
       "9    5781373 2025-07-14 14:00:00          2        0.07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#find most recent folder (up to 3 days back) with channel_rt files\n",
    "valid_prefix = None\n",
    "published_runs = set()\n",
    "for delta in range(4):\n",
    "    dt     = today - timedelta(days=delta)\n",
    "    prefix = f\"{s3_bucket}/nwm.{dt:%Y%m%d}/short_range/\"\n",
    "    try:\n",
    "        all_files = fs.find(prefix)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    runs = {\n",
    "        int(m.group(1))\n",
    "        for f in all_files\n",
    "        if f.endswith(\".conus.nc\")\n",
    "        and \".channel_rt.\" in f\n",
    "        and (m := re.search(r\"nwm\\.t(\\d{2})z\", os.path.basename(f)))\n",
    "    }\n",
    "    if runs:\n",
    "        valid_prefix   = prefix\n",
    "        published_runs = runs\n",
    "        break\n",
    "\n",
    "if not valid_prefix:\n",
    "    raise RuntimeError(\"No short_range/channel_rt folder in last 4 days\")\n",
    "\n",
    "# clear any cached listings so we see newly uploaded runs\n",
    "fs.invalidate_cache(valid_prefix)\n",
    "\n",
    "# rebuild channel_files with bare keys\n",
    "channel_files = [\n",
    "    f for f in fs.find(valid_prefix)\n",
    "    if f.endswith(\".conus.nc\") and \".channel_rt.\" in f\n",
    "]\n",
    "\n",
    "print(f\"Using folder {valid_prefix} with cycles: {sorted(published_runs)}Z\")\n",
    "\n",
    "# build a lookup of (run_hr, lead_hr) → bare S3 key\n",
    "run_lead_map = {}\n",
    "for path in channel_files:\n",
    "    fn     = os.path.basename(path)\n",
    "    m_run  = re.search(r\"nwm\\.t(\\d{2})z\", fn)\n",
    "    m_lead = re.search(r\"\\.f(\\d{3})\\.\", fn)\n",
    "    if m_run and m_lead:\n",
    "        run_hr, lead_hr = int(m_run.group(1)), int(m_lead.group(1))\n",
    "        if 1 <= lead_hr <= max_lead_hours:\n",
    "            run_lead_map[(run_hr, lead_hr)] = path  # <— no \"s3://\"\n",
    "\n",
    "# parse the prefix date for full datetimes\n",
    "date_str  = valid_prefix.split(\"/\")[1].split(\".\")[1]  # e.g. \"20250708\"\n",
    "prefix_dt = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "\n",
    "# Latest‐cycle forecasts (tXXZ → f001–f010)\n",
    "latest_run_hr = max(run for run, _ in run_lead_map)\n",
    "latest_run_dt = prefix_dt + timedelta(hours=latest_run_hr)\n",
    "\n",
    "#comids_int       = [int(c) for c in comids]\n",
    "records_current  = []\n",
    "chosen_run_hr    = None\n",
    "\n",
    "records_current = []\n",
    "for run_hr in sorted(published_runs, reverse=True):\n",
    "    run_dt = prefix_dt + timedelta(hours=run_hr)\n",
    "    temp   = []\n",
    "    for lead_hr in range(1, max_lead_hours+1):\n",
    "        key = run_lead_map.get((run_hr, lead_hr))\n",
    "        if not key:\n",
    "            continue\n",
    "\n",
    "        url = f's3://{key}'\n",
    "        ds  = xr.open_dataset(\n",
    "            url,\n",
    "            engine='h5netcdf',\n",
    "            storage_options={'anon':True}\n",
    "        )\n",
    "\n",
    "        # filter by your crosswalk feature_ids\n",
    "        ds_ids      = ds['feature_id'].values.astype(int)\n",
    "        present_ids = [fid for fid in nwm_ids_int if fid in ds_ids]\n",
    "        if not present_ids:\n",
    "            continue\n",
    "\n",
    "        da = ds[variable].sel(feature_id=present_ids).load()\n",
    "        df = da.to_dataframe().reset_index()\n",
    "        df['feature_id'] = df['feature_id'].astype(int).astype(str)\n",
    "        df = (\n",
    "            df\n",
    "            .set_index('feature_id')\n",
    "            .reindex([str(fid) for fid in nwm_ids_int])\n",
    "            .reset_index()\n",
    "        )\n",
    "        df['valid_time']   = run_dt + timedelta(hours=lead_hr)\n",
    "        df['forecast_run'] = run_dt\n",
    "        df['lead_hour']    = lead_hr\n",
    "        temp.append(df)\n",
    "\n",
    "    if temp:\n",
    "        df_current = pd.concat(temp, ignore_index=True)\n",
    "        print(f\"✔ Using t{run_hr:02d}Z run for current forecasts\")\n",
    "        display(df_current[['feature_id','valid_time','lead_hour',variable]].head(5))\n",
    "        break\n",
    "\n",
    "# pick the valid_time closest to “now”\n",
    "now = datetime.utcnow()\n",
    "valid_time_current = min(\n",
    "    df_current['valid_time'].unique(),\n",
    "    key=lambda vt: abs(vt - now)\n",
    ")\n",
    "print(f\"Ensemble valid_time chosen: {valid_time_current}\")\n",
    "\n",
    "#Pull the 10‐member ensemble for that single valid_time → df_ensemble_current\n",
    "\n",
    "records_ensemble = []\n",
    "for lead_hr in range(1, max_lead_hours+1):\n",
    "    run_dt = valid_time_current - timedelta(hours=lead_hr)\n",
    "    key    = run_lead_map.get((run_dt.hour, lead_hr))\n",
    "    if not key:\n",
    "        continue\n",
    "\n",
    "    url = f's3://{key}'\n",
    "    ds  = xr.open_dataset(\n",
    "        url,\n",
    "        engine='h5netcdf',\n",
    "        storage_options={'anon':True}\n",
    "    )\n",
    "\n",
    "    ds_ids      = ds['feature_id'].values.astype(int)\n",
    "    present_ids = [fid for fid in nwm_ids_int if fid in ds_ids]\n",
    "    if not present_ids:\n",
    "        continue\n",
    "\n",
    "    da = ds[variable].sel(feature_id=present_ids).load()\n",
    "    df = da.to_dataframe().reset_index()\n",
    "    df['feature_id'] = df['feature_id'].astype(int).astype(str)\n",
    "    df = (\n",
    "        df\n",
    "        .set_index('feature_id')\n",
    "        .reindex([str(fid) for fid in nwm_ids_int])\n",
    "        .reset_index()\n",
    "    )\n",
    "    df['valid_time']   = valid_time_current\n",
    "    df['forecast_run'] = run_dt\n",
    "    df['lead_hour']    = lead_hr\n",
    "    records_ensemble.append(df)\n",
    "\n",
    "df_ensemble_current = pd.concat(records_ensemble, ignore_index=True)\n",
    "print(\"✔ Got 10-member ensemble for current time\")\n",
    "display(df_ensemble_current[['feature_id','forecast_run','lead_hour',variable]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaf2c6f",
   "metadata": {},
   "source": [
    "#### 5. Get instantaneous gage data (discharge) for current time from USGS gages on NWM reaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9e19b587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>00060_15-minute updates</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site_no</th>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">08105872</th>\n",
       "      <th>2025-07-14 05:00:00+00:00</th>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-14 05:05:00+00:00</th>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-14 05:10:00+00:00</th>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-14 05:15:00+00:00</th>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-14 05:20:00+00:00</th>\n",
       "      <td>213.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    00060_15-minute updates\n",
       "site_no  datetime                                          \n",
       "08105872 2025-07-14 05:00:00+00:00                    213.0\n",
       "         2025-07-14 05:05:00+00:00                    213.0\n",
       "         2025-07-14 05:10:00+00:00                    213.0\n",
       "         2025-07-14 05:15:00+00:00                    213.0\n",
       "         2025-07-14 05:20:00+00:00                    213.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Pull in USGS Discharge Data for today\n",
    "parameterCode = \"00060\"   # discharge\n",
    "today         = date.today().isoformat()   # e.g. \"2025-07-09\"\n",
    "\n",
    "discharge_df, meta = nwis.get_iv(\n",
    "    sites=site_ids,\n",
    "    parameterCd=parameterCode,\n",
    "    start=today,\n",
    "    end=today\n",
    ")\n",
    "\n",
    "#keep only the first column (discharge column)\n",
    "df_iv = discharge_df.iloc[:, :1]\n",
    "\n",
    "# View\n",
    "display(df_iv.head())\n",
    "\n",
    "# keep only the discharge column and reset index (site_id and datetime columns were in a multi-index)\n",
    "df_iv = discharge_df.iloc[:, :1].reset_index()\n",
    "df_iv = df_iv.rename(columns={df_iv.columns[-1]: \"discharge_obs_cfs\"})\n",
    "\n",
    "obs_current = (\n",
    "    df_iv[[\"site_no\", \"discharge_obs_cfs\"]]\n",
    "      .drop_duplicates(subset=\"site_no\")\n",
    "      .rename(columns={\"site_no\": \"usgs_site_code\"})\n",
    ")\n",
    "#Convert from cfs to m3/s\n",
    "obs_current[\"discharge_obs_m3s\"] = obs_current[\"discharge_obs_cfs\"] * CFS_TO_M3S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841a004c",
   "metadata": {},
   "source": [
    "#### 6. Determine CRPS and Percentage Bias for Reaches with Gage Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9d60ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usgs_site_code feature_id  discharge_obs_m3s  ensemble_mean_m3s  bias_m3s    pct_bias  crps_m3s\n",
      "      08172400    1631087                NaN           0.526667       NaN         NaN       NaN\n",
      "      08105888    5671187                NaN           9.906666       NaN         NaN       NaN\n",
      "      08105883    5671189                NaN           7.287778       NaN         NaN       NaN\n",
      "      08105872    5671619           6.031488           3.870000 -2.161488  -35.836734  1.723464\n",
      "      08105886    5673157           0.219172           0.156667 -0.062506  -28.518979  0.039233\n",
      "      08158700    5780099           0.175281           0.214444  0.039163   22.343036  0.026817\n",
      "      08154700    5781189                NaN           1.627778       NaN         NaN       NaN\n",
      "      08158380    5781203           0.043042           3.130000  3.086958 7172.033182  0.616094\n",
      "      08158200    5781217                NaN           4.603333       NaN         NaN       NaN\n",
      "      08156675    5781223                NaN           1.842222       NaN         NaN       NaN\n",
      "      08155200    5781265                NaN           1.375556       NaN         NaN       NaN\n",
      "      08158600    5781285                NaN           5.872222       NaN         NaN       NaN\n",
      "      08158035    5781319           0.022937           1.144444  1.121508 4889.589288  0.349656\n",
      "      08155240    5781325                NaN           1.694444       NaN         NaN       NaN\n",
      "      08155300    5781337                NaN           2.415556       NaN         NaN       NaN\n",
      "      08159000    5781369                NaN           4.874444       NaN         NaN       NaN\n",
      "      08158840    5781373           0.000000           0.544444  0.544444         inf  0.191358\n",
      "      08158810    5781401           0.074473           0.156667  0.082193  110.366198  0.040959\n",
      "      08158860    5781407                NaN           1.410000       NaN         NaN       NaN\n",
      "      08158813    5781417                NaN           0.176667       NaN         NaN       NaN\n",
      "      08158827    5781431                NaN           1.222222       NaN         NaN       NaN\n",
      "      08156800    5781703                NaN           3.665555       NaN         NaN       NaN\n",
      "      08155541    5781709           0.015008           0.377778  0.362770 2417.187928  0.096350\n",
      "      08155400    5781711                NaN           2.726667       NaN         NaN       NaN\n",
      "      08158970    5781731           0.242675           3.030000  2.787325 1148.581538  1.032666\n",
      "      08158000    5781917                NaN          22.363333       NaN         NaN       NaN\n"
     ]
    }
   ],
   "source": [
    "# Calculate short range ensemble mean\n",
    "en_wide = (\n",
    "    df_ensemble_current\n",
    "      .pivot(index=\"feature_id\", columns=\"lead_hour\", values=variable)\n",
    "      .rename_axis(columns=None)\n",
    "      .reset_index()\n",
    ")\n",
    "member_cols = sorted(c for c in en_wide.columns if isinstance(c, int))\n",
    "member_names = [f\"m{c}\" for c in member_cols]\n",
    "en_wide = en_wide.rename(columns={c: f\"m{c}\" for c in member_cols})\n",
    "en_wide[\"ensemble_mean_m3s\"] = en_wide[member_names].mean(axis=1)\n",
    "\n",
    "# unify crosswalk IDs as strings\n",
    "cw_small = (\n",
    "    cw[[\"nwm_feature_id\", \"usgs_site_code\"]]\n",
    "      .assign(nwm_feature_id=lambda df: df[\"nwm_feature_id\"].astype(str))\n",
    "      .rename(columns={\"nwm_feature_id\": \"feature_id\"})\n",
    ")\n",
    "\n",
    "# Ensure en_wide.feature_id is a string\n",
    "en_wide['feature_id'] = en_wide['feature_id'].astype(str)\n",
    "\n",
    "# Build cw_small with string IDs (as before)\n",
    "cw_small = (\n",
    "    cw[['nwm_feature_id','usgs_site_code']]\n",
    "      .assign(nwm_feature_id=lambda df: df['nwm_feature_id'].astype(str))\n",
    "      .rename(columns={'nwm_feature_id':'feature_id'})\n",
    ")\n",
    "\n",
    "# Merge\n",
    "df = (\n",
    "    en_wide\n",
    "      .merge(cw_small, on='feature_id')\n",
    "      .merge(obs_current, on='usgs_site_code')\n",
    ")\n",
    "df[\"bias_m3s\"] = df[\"ensemble_mean_m3s\"] - df[\"discharge_obs_m3s\"]\n",
    "df[\"pct_bias\"] = df[\"bias_m3s\"] / df[\"discharge_obs_m3s\"] * 100\n",
    "\n",
    "def compute_crps(row):\n",
    "    fc = np.array([row[m] for m in member_names], dtype=float)\n",
    "    da_fc = xr.DataArray(\n",
    "        data=fc[np.newaxis, :],\n",
    "        dims=[\"time\", \"ensemble_member\"],\n",
    "        coords={\"time\": [0], \"ensemble_member\": np.arange(fc.size)},\n",
    "    )\n",
    "    da_obs = xr.DataArray(\n",
    "        data=[float(row[\"discharge_obs_m3s\"])],\n",
    "        dims=[\"time\"],\n",
    "        coords={\"time\": [0]},\n",
    "    )\n",
    "    return float(\n",
    "        crps_for_ensemble(\n",
    "            da_fc,\n",
    "            da_obs,\n",
    "            ensemble_member_dim=\"ensemble_member\",\n",
    "            method=\"ecdf\",\n",
    "        ).values\n",
    "    )\n",
    "\n",
    "df[\"crps_m3s\"] = df.apply(compute_crps, axis=1)\n",
    "\n",
    "# Results\n",
    "result = df[\n",
    "    [\n",
    "        \"usgs_site_code\",\n",
    "        \"feature_id\",\n",
    "        \"discharge_obs_m3s\",\n",
    "        \"ensemble_mean_m3s\",\n",
    "        \"bias_m3s\",\n",
    "        \"pct_bias\",\n",
    "        \"crps_m3s\",\n",
    "    ]\n",
    "]\n",
    "print(result.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nwm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
